{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local[4]').set('spark.jars.packages', 'graphframes:graphframes:0.8.0-spark2.4-s_2.11')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "244e4df2edd91029d78a89ade0b553e5",
     "grade": false,
     "grade_id": "cell-f8987996be9f1238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Utilización del servicio de alquiler de bicicletas en Toronto en el año 2018\n",
    "\n",
    "### Disponible en Kaggle en:\n",
    "https://www.kaggle.com/jackywang529/toronto-bikeshare-data\n",
    "\n",
    "\n",
    "El propósito de este análisis es utilizar los conjuntos de datos trimestrales del año 2018 de la empresa de alquiler de bicicletas en Toronto. Se trata de *cuatro* conjuntos de datos separados, que incluyen entre 178.559 y 822.536 observaciones, siempre con nueve variables. Cada fila representa un viaje realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a6b4dc108ddf890c659e33701965428",
     "grade": false,
     "grade_id": "cell-f74d7bfd01811789",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Variables y significado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cb790eed3719dc8d6cfd639c9176b4a",
     "grade": false,
     "grade_id": "cell-9cfb34982bd4eb04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Las variables utilizadas para describir cada viaje son:\n",
    "\n",
    "* trip_id – identificador global del viaje\n",
    "* trip_duration_seconds – duración del viaje en segundos\n",
    "* from_station_id – identificador numérico de la estación de origen\n",
    "* trip_start_time – instante (timestamp) en el que se inició el viaje\n",
    "* from_station_name – nombre de la intersección más cercana a la estación origen\n",
    "* trip_stop_time – instante (timestamp) en el que finalizó el viaje\n",
    "* to_station_id – identificador numérico de la estación de destino\n",
    "* to_station_name – nombre de la intersección más cercana a la estación de destino\n",
    "* user_type – tipo de usuario (indicador binario): miembro registrado con cuota anual / usuario ocasional no registrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nombre completo del alumno:**  Sara Arribas Martín "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76dc5b331cac3113e9e77522358617bf",
     "grade": false,
     "grade_id": "cell-b4f9c37a2b92d2e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**INSTRUCCIONES**: en cada celda debes responder a la pregunta formulada, asegurándote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del cálculo quede guardado exactamente en la variable que venía inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). **No olvides borrar la línea *raise NotImplementedError()* de cada celda cuando hayas completado la solución de esa celda y quieras probarla**.\n",
    "\n",
    "Después de cada celda evaluable verás una celda con código. Ejecútala (no modifiques su código) y te dirá si tu solución es correcta o no. En caso de ser correcta, se ejecutará correctamente y no mostrará nada, pero si no lo es mostrará un error. Además de esas pruebas, se realizarán algunas más (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la solución correcta o no. Asegúrate de que, al menos, todas las celdas indican que el código es correcto antes de enviar el notebook terminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bae739df33929bae8d756987e80caf8",
     "grade": false,
     "grade_id": "cell-69ec0993eeaff3ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sobre los cuatro datasets anteriores (Bike Share Toronto Ridership_Q1 2018.csv hasta Q4) se pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>PREGUNTA:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 punto)** Ejercicio 1\n",
    "\n",
    "* Leer por separado cada uno de ellos (sin cachear), tratando de que Spark infiera el tipo de dato de cada columna, y **unirlos en un solo DF** que tampoco debe ser cacheada todavía, ya que en el siguiente paso aún realizaremos otro pre-procesamiento.\n",
    "* Los cuatro contienen las mismas columnas por lo que no habrá problemas para utilizar la operación `union` encadenada tres veces para crear el DF final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c54cebbd008d0e53dfc6d9068950f0d0",
     "grade": false,
     "grade_id": "read_csv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\n",
    "# Primer CSV\n",
    "tripsQ1 = accidentesDF = spark.read\\\n",
    "                 .option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(\"C:/Users/sara.arribas/Documents/Big Data/EjerciciosPostSpark/Teoria y ejercicios/Ejercicios/Bike Share Toronto Ridership_Q1 2018.csv\")\n",
    "# Segundo CSV\n",
    "tripsQ2 = accidentesDF = spark.read\\\n",
    "                 .option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(\"C:/Users/sara.arribas/Documents/Big Data/EjerciciosPostSpark/Teoria y ejercicios/Ejercicios/Bike Share Toronto Ridership_Q2 2018.csv\") \n",
    "# Tercer CSV\n",
    "tripsQ3 = accidentesDF = spark.read\\\n",
    "                 .option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(\"C:/Users/sara.arribas/Documents/Big Data/EjerciciosPostSpark/Teoria y ejercicios/Ejercicios/Bike Share Toronto Ridership_Q3 2018.csv\") \n",
    "# Cuarto CSV\n",
    "tripsQ4 = accidentesDF = spark.read\\\n",
    "                 .option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(\"C:/Users/sara.arribas/Documents/Big Data/EjerciciosPostSpark/Teoria y ejercicios/Ejercicios/Bike Share Toronto Ridership_Q4 2018.csv\")  \n",
    "\n",
    "\n",
    "# Unión de todos\n",
    "tripsTorontoRawDF = tripsQ1.union(tripsQ2).union(tripsQ3).union(tripsQ4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6fa646bfe97c4d7d321099133d99e4",
     "grade": true,
     "grade_id": "read_csv_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "assert(tripsTorontoRawDF.count() == 1922955)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>PREGUNTA:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35c19b58ca86dc12ba34133928db4cdc",
     "grade": false,
     "grade_id": "cell-b90f5b934eda250e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 2\n",
    "\n",
    "* Las columnas `trip_start_time` y `trip_stop_time` son en realidad instantes de tiempo que Spark debería procesar como timestamp. Reemplaza **ambas columnas** por su versión convertida a timestamp, utilizando `withColumn` y donde el nuevo valor de la columna viene dado por el siguiente código:\n",
    "        F.from_unixtime(F.unix_timestamp('nombreColumna', 'MM/dd/yyyy HH:mm')).cast(\"timestamp\"))\n",
    "El DF resultante debe ser almacenado en la variable `tripsTorontoDF`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9129c1d06eef70a5b6922585902dfa36",
     "grade": false,
     "grade_id": "convert_timestamp",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+\n",
      "|trip_id|trip_duration_seconds|from_station_id|    trip_start_time|   from_station_name|     trip_stop_time|to_station_id|     to_station_name|    user_type|\n",
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+\n",
      "|2383648|                  393|           7018|2018-01-01 00:47:00|Bremner Blvd / Re...|2018-01-01 00:54:00|         7176|Bathurst St / For...|Annual Member|\n",
      "|2383649|                  625|           7184|2018-01-01 00:52:00|Ossington Ave / C...|2018-01-01 01:03:00|         7191|Central Tech  (Ha...|Annual Member|\n",
      "|2383650|                  233|           7235|2018-01-01 00:55:00|Bay St / College ...|2018-01-01 00:59:00|         7021|  Bay St / Albert St|Annual Member|\n",
      "|2383651|                 1138|           7202|2018-01-01 00:57:00|Queen St W / York...|2018-01-01 01:16:00|         7020|Phoebe St / Spadi...|Annual Member|\n",
      "|2383652|                  703|           7004|2018-01-01 01:00:00|University Ave / ...|2018-01-01 01:12:00|         7060|Princess St / Ade...|Annual Member|\n",
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\") # Soluciones Nuria\n",
    "\n",
    "tripsTorontoDF = tripsTorontoRawDF\\\n",
    "                 .withColumn(\"trip_start_time\", F.from_unixtime(F.unix_timestamp(\"trip_start_time\",'MM/dd/yyyy HH:mm')).cast(\"timestamp\"))\\\n",
    "                 .withColumn(\"trip_stop_time\", F.from_unixtime(F.unix_timestamp(\"trip_stop_time\",'MM/dd/yyyy HH:mm')).cast(\"timestamp\"))\n",
    "\n",
    "tripsTorontoDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ebd685fd8c8fcd5062ecd1c29adcd4b",
     "grade": true,
     "grade_id": "convert_timestamp_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "typesDict = dict(tripsTorontoDF.dtypes)\n",
    "assert(typesDict[\"trip_start_time\"] == \"timestamp\") \n",
    "assert(typesDict[\"trip_stop_time\"] == \"timestamp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>PREGUNTA:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d11d72889323abc3fa6626ed1da257f",
     "grade": false,
     "grade_id": "cell-fc88821f19453a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 3\n",
    "\n",
    "Partiendo de `tripsTorontoDF`, realizar las siguientes transformaciones encadenadas en este orden para crear un nuevo DF:\n",
    "* Primero, debemos quedarnos solamente con las filas donde `trip_start_time` no sea null.\n",
    "* Sobre el DF resultado de lo anterior, añadir una columna adicional **Mes** y con el mes representado en **trip_start_time**. Dicha columna será de tipo entero y se puede obtener usando `withColumn` con la función `F.month(\"colName\")`, que recibe un nombre de columna y devuelve un objeto columna de enteros que van de 1 a 12. \n",
    "* Encadenar esta transformación con otra en la que la columna **Mes** sea reemplazada por su traducción a  cadena de caracteres de 3 letras, siendo la correspondencia 1: Ene, 2: Feb, 3: Mar, 4: Abr, 5: May, 6: Jun, 7: Jul, 8: Ago, 9: Sep, 10: Oct, 11: Nov, 12: Dic.\n",
    "* Finalmente, añadir una nueva columna **Hora** que contenga la hora de inicio del viaje, aplicando `withColumn` con la función `F.hour(\"colName\")` que recibe un nombre de columna y recibe un objeto columna de enteros de 0 a 23.\n",
    "* El DF resultante de todas estas transformaciones debe guardarse en la variable `tripsTorontoTimesDF`, que por tanto tendrá 2 columnas más que el DF original `tripsTorontoDF`, y que debe quedar **cacheado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2aa969fc933e984b995caf9a857feede",
     "grade": false,
     "grade_id": "renombrar_mes_hora",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SARA~1.ARR\\AppData\\Local\\Temp/ipykernel_6296/1490658774.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#F.when(F.col(\"Mes\") == 1, \"1: Ene\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtripsTorontoTimesDF2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtripsTorontoDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trip_start_time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misNull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                                     \u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trip_start_time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                     \u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mes\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_meses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   2452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2453\u001b[0m         \"\"\"\n\u001b[1;32m-> 2454\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"col should be Column\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2455\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "# imports......\n",
    "list_meses = [\"1: Ene\", \"2: Feb\", \"3: Mar\", \"4: Abr\", \"5: May\", \"6: Jun\", \"7: Jul\", \"8: Ago\", \"9: Sep\", \"10: Oct\", \"11: Nov\", \"12: Dic\"]\n",
    "\n",
    "#F.when(F.col(\"Mes\") == 1, \"1: Ene\")\n",
    "\n",
    "tripsTorontoTimesDF2 = tripsTorontoDF.where(~F.col(\"trip_start_time\").isNull())\\\n",
    "                                    .withColumn(\"Mes\", F.month(\"trip_start_time\"))\\\n",
    "                                    .withColumn(\"Mes\", (F.when((F.col(\"Mes\") == (c+1)), list_meses[c+1]) for c in range(13)))\\\n",
    "                                    .withColumn(\"Hora\", F.hour(\"trip_start_time\"))\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsTorontoTimesDF = tripsTorontoDF.where(F.col(\"trip_start_time\").isNotNull())\\\n",
    "                                    .withColumn(\"Mes\", F.month(\"trip_start_time\"))\\\n",
    "                                    .withColumn(\"Mes\", F.date_format(F.to_date(F.col(\"Mes\").cast(\"string\"), \"MM\"),\"MMM\"))\\\n",
    "                                    .withColumn(\"Hora\", F.hour(\"trip_start_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b60aed54e852d77c7fa8482a4c34379c",
     "grade": true,
     "grade_id": "renombrar_mes_hora_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SARA~1.ARR\\AppData\\Local\\Temp/ipykernel_6296/4083805103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtripsPerMonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m281219\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtripsPerMonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m83324\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtripsPerMonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m43859\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtripsPerMonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m49731\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtripsPerMonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m286316\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tripsPerMonth = tripsTorontoTimesDF.groupBy(\"Mes\").count().sort(\"Mes\").collect()\n",
    "assert(tripsPerMonth[0][\"count\"] == 94783)\n",
    "assert(tripsPerMonth[1][\"count\"] == 281219)\n",
    "assert(tripsPerMonth[2][\"count\"] == 83324)\n",
    "assert(tripsPerMonth[3][\"count\"] == 43859)\n",
    "assert(tripsPerMonth[4][\"count\"] == 49731)\n",
    "assert(tripsPerMonth[5][\"count\"] == 286316)\n",
    "assert(tripsPerMonth[6][\"count\"] == 250837)\n",
    "assert((tripsPerMonth[7][\"count\"] == 84959) | (tripsPerMonth[7][\"count\"] == 84969))\n",
    "assert(tripsPerMonth[8][\"count\"] == 212750)\n",
    "assert(tripsPerMonth[9][\"count\"] == 104287)\n",
    "assert(tripsPerMonth[10][\"count\"] == 175879)\n",
    "assert(tripsPerMonth[11][\"count\"] == 255001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>PREGUNTA:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f98c8387ad8a683f0ea2f1c6e441e07a",
     "grade": false,
     "grade_id": "cell-a71a6b17b1e0d613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 4\n",
    "\n",
    "* Partiendo de `tripsTorontoTimesDF`, crear un nuevo DataFrame con **tantas filas como horas tiene el día, y tantas columnas como meses del año** de manera que cada celda indique el **número de viajes** que comenzaron a esa hora en ese mes del año. Guardar el resultado en la variable `tripsPerMonthAndHourDF`, cuyas filas deben quedar ordenadas en base a la hora (de 0 a 23), y cuyas columnas deben estar también ordenadas desde `\"Ene\"` a `\"Dic\"`, con `\"Hora\"` como primera columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "416095b927a3c16ca9843df1228e43d3",
     "grade": false,
     "grade_id": "numero_categorias",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "|Hora| Ene| Feb|  Mar|  Abr|  May|  Jun|  Jul|  Ago|  Sep|  Oct|  Nov| Dic|\n",
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "|   0| 425| 412|  689|  770| 1913| 2859| 3418| 2912| 2623| 1419|  888| 782|\n",
      "|   1| 266| 308|  434|  493| 1180| 1725| 1991| 1831| 1689|  943|  637| 525|\n",
      "|   2| 201| 183|  308|  374|  804| 1274| 1356| 1360| 1344|  684|  442| 417|\n",
      "|   3|  91| 101|  156|  130|  361|  587|  646|  595|  632|  245|  211| 164|\n",
      "|   4|  49|  56|  133|  114|  227|  463|  494|  504|  467|  264|  253| 187|\n",
      "|   5| 198| 226|  348|  381|  627|  877| 1121| 1110| 1032|  860|  569| 373|\n",
      "|   6| 603| 668|  995| 1092| 2043| 2802| 3232| 3088| 2800| 2373| 1745|1082|\n",
      "|   7|1742|2011| 3303| 3436| 6626| 8209| 8978| 8146| 8130| 6217| 4286|2914|\n",
      "|   8|5001|5199| 8682| 9825|17855|20602|23931|22475|21216|17825|11720|8293|\n",
      "|   9|3728|3769| 6497| 6790|12063|14044|16089|14978|14710|12381| 8314|6287|\n",
      "|  10|1975|2017| 3557| 3624| 7830| 8641|10195|10306| 9873| 6935| 4100|3634|\n",
      "|  11|1873|1893| 3747| 3865| 9278|10121|11823|12570|11549| 7437| 4444|3900|\n",
      "|  12|2259|2386| 4548| 4761|11427|12701|14796|15539|14362| 9308| 5445|4696|\n",
      "|  13|2117|2334| 4379| 4878|12117|13189|15492|16393|14755| 9089| 5296|4908|\n",
      "|  14|2002|2269| 4271| 4735|11909|13186|14915|15775|14261| 8573| 4910|4786|\n",
      "|  15|2483|2855| 4933| 5690|13518|14495|16429|16923|16075| 9899| 5835|5362|\n",
      "|  16|3936|4482| 7333| 8475|18306|19759|22815|22772|21378|14895| 8682|7146|\n",
      "|  17|4981|6320|10064|11456|25144|28216|32028|31734|29342|21593|11944|9043|\n",
      "|  18|3314|4383| 7332| 8440|19013|22257|25347|25571|22663|16048| 8319|6396|\n",
      "|  19|2147|2556| 4556| 5487|14104|17638|19146|18937|15996| 9865| 5228|4046|\n",
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "\n",
    "tripsPerMonthAndHourDF_bis = tripsTorontoTimesDF.groupBy(\"Hora\").pivot(\"Mes\").agg(F.count(\"trip_start_time\"))\\\n",
    "                                            .sort(\"Hora\")\n",
    "\n",
    "tripsPerMonthAndHourDF = tripsPerMonthAndHourDF_bis.select(\"Hora\",F.col(\"Jan\").alias(\"Ene\"),\"Feb\",\"Mar\",F.col(\"Apr\").alias(\"Abr\")\\\n",
    "                                                           ,\"May\",\"Jun\",\"Jul\",F.col(\"Aug\").alias(\"Ago\"),\"Sep\",\"Oct\",\"Nov\",\\\n",
    "                                                           F.col(\"Dec\").alias(\"Dic\"))\n",
    "\n",
    "tripsPerMonthAndHourDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d64ff89bcbd46871e937ae34db834496",
     "grade": true,
     "grade_id": "numero_categorias_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(tripsPerMonthAndHourDF.columns) == 13)\n",
    "assert(tripsPerMonthAndHourDF.columns[0] == \"Hora\")\n",
    "assert(tripsPerMonthAndHourDF.columns[12] == \"Dic\")\n",
    "assert(tripsPerMonthAndHourDF.count() == 24)\n",
    "todasHoras = tripsPerMonthAndHourDF.collect()\n",
    "assert((todasHoras[0][\"Hora\"] == 0) & (todasHoras[0][\"Dic\"]==782))\n",
    "assert((todasHoras[23][\"Hora\"] == 23) & (todasHoras[23][\"Dic\"]==1208))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>PREGUNTA:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d2b0a3fb505c65793ee15bf17e87e87",
     "grade": false,
     "grade_id": "cell-c5ec05706eccd480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 puntos)** Ejercicio 5. \n",
    "\n",
    "Partiendo de `tripsTorontoTimesDF` definido anteriormente, añadir las siguientes columnas:\n",
    "\n",
    "* Primero, tres columnas adicionales llamadas `dur_media`, `dur_min`, `dur_max` que contengan, respectivamente, **la duración media, mínima y máxima de los viajes que parten de esa misma estación de origen (from_station_id) a esa misma hora y en ese mismo mes del año**. Es decir, queremos una columna extra para que podamos tener, junto a cada viaje, información agregada de los viajes similares, entendidos como aquellos que salieron a la misma hora de la misma estación. **No se debe utilizar JOIN sino solo funciones de ventana**.\n",
    "* A continuación, otra columna adicional `diff_dur_porc` que contenga la diferencia, medida en porcentaje, entre la duración del viaje y la duración media de los viajes similares calculada en el apartado anterior. Dicha diferencia debe calcularse como la resta de la duración del viaje menos la duración media, dividida entre la duración media y multiplicada por 100. El resultado debe obtenerse aplicando operaciones aritméticas con columnas existentes, **sin utilizar `when`**.\n",
    "* El DF resultante con las 4 columnas nuevas que hemos añadido debe almacenarse en la variable `tripsTorontoExtraInfoDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsTorontoTimesDF.select(\"from_station_id\",\"trip_start_time\", \"trip_stop_time\")\\\n",
    "                   .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14773754aebd257287c3ab4a00b00379",
     "grade": false,
     "grade_id": "ventana",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "windowHoraMesEstacion = Window().partitionBy(\"from_station_id\", \"Hora\",\"Mes\")\n",
    "                                       \n",
    "tripsTorontoExtraInfoDF = tripsTorontoTimesDF.withColumn(\"dur_media\", F.mean(\"trip_duration_seconds\").over(windowHoraMesEstacion))\\\n",
    "                                            .withColumn(\"dur_min\", F.min(\"trip_duration_seconds\").over(windowHoraMesEstacion))\\\n",
    "                                            .withColumn(\"dur_max\", F.max(\"trip_duration_seconds\").over(windowHoraMesEstacion))\\\n",
    "                                            .withColumn(\"diff_dur_porc\", (F.col(\"trip_duration_seconds\")-F.col(\"dur_media\"))/(F.col(\"dur_media\")*100))\n",
    "                                               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "729b30b98cb70cb301206a9bce962a58",
     "grade": true,
     "grade_id": "ventana_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "r = tripsTorontoExtraInfoDF.where(\"trip_id = '2970611'\").head()\n",
    "assert(r.dur_media - 783.366666667 < 0.001)\n",
    "assert(r.diff_dur_porc - 44.24918088591975 < 0.001)\n",
    "assert(r.dur_min == 167)\n",
    "assert(r.dur_max == 2333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>PREGUNTA:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d197cc479ae5510f149b5430d62a157",
     "grade": false,
     "grade_id": "cell-9ebe35c4b4325269",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 puntos)** Ejercicio 6\n",
    "\n",
    "* Partiendo de `tripsTorontoTimesDF`, crear un **grafo** llamado `bikeGraph` utilizando como identificador de los vértices los identificadores de las estaciones. Construye primero un DF con todos los identificadores de las estaciones, simplemente seleccionando **from_station_id**, renombrando adecuadamente el nombre de columna. Puedes almacenar este DF en la variable `verticesDF`. También tendrás que renombrar las columnas **from_station_id** y **to_station_id** en el DF de aristas, para el que además deberás seleccionar solo dichas columnas y quitar las filas repetidas ya que solo necesitamos considerar una vez cada ruta (cada pareja de estación inicial y final). Puedes almacenar el resultado del renombramiento y la eliminación de repetidos en la variable `edgesDF`.\n",
    "* Una vez creado, aplica el algoritmo `pageRank` pasando como único parámetro `maxIter = 5`. El algoritmo puede llegar a emplear más de 10 minutos. \n",
    "* Almacena el grafo devuelto por dicha función en la variable `pageRankGraph`, recupera el DF de sus vértices, ordénalo descendentemente en base a la columna `pagerank` y almacena el resultado en la variable `sortedPageRankGraphVerticesDF`\n",
    "* Obtén el identificador de la estación más relevante (con mayor valor de la métrica pageRank, que ocupará la primera fila tras la ordenación), y almacena dicho identificador en la variable `id_mas_relevante`.\n",
    "* Crea un nuevo DF de una sola fila y tres columnas llamadas `dur_media`, `dur_min` y `dur_max` con la duración **media, mínima y máxima** de los viajes de `tripsTorontoTimesDF` que **empiezan** en dicha estación (sin tener en cuenta distinción de horas o meses). **No debe usarse la función `withColumn` sino crear las columnas al vuelo con `select`**. Debe quedar almacenado en la variable `durEstMasRelevantesDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc1f29ab4015788d03e8e01be66ea200",
     "grade": false,
     "grade_id": "graph",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"/tmp\")\n",
    "\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "verticesDF = tripsTorontoTimesDF.select(F.col(\"from_station_id\").alias(\"id\")).distinct()\n",
    "\n",
    "edgesDF = tripsTorontoTimesDF.withColumnRenamed(\"from_station_id\",\"src\")\\\n",
    "                   .withColumnRenamed(\"to_station_id\", \"dst\")\\\n",
    "                   .select(\"src\", \"dst\")\\\n",
    "                   .distinct()\\\n",
    "                   .cache()\n",
    "\n",
    "bikeGraph = GraphFrame(verticesDF, edgesDF)\n",
    "\n",
    "\n",
    "pageRankGraph = bikeGraph.pageRank(maxIter = 5) \n",
    "\n",
    "sortedPageRankGraphVerticesDF = pageRankGraph.vertices.orderBy(F.col(\"pagerank\").desc())\n",
    "\n",
    "id_mas_relevante = sortedPageRankGraphVerticesDF.first()[\"id\"]\n",
    "\n",
    "durEstMasRelevantesDF = tripsTorontoTimesDF.where(F.col(\"from_station_id\") == \"id_mas_relevante\")\\\n",
    "                                           .select(F.mean(\"trip_duration_seconds\").alias(\"dur_media\"),\\\n",
    "                                                   F.min(\"trip_duration_seconds\").alias(\"dur_min\"),\\\n",
    "                                                   F.max(\"trip_duration_seconds\").alias(\"dur_max\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cce36154f8b55fd019b7f285e1273958",
     "grade": true,
     "grade_id": "graph_tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SARA~1.ARR\\AppData\\Local\\Temp/ipykernel_6296/1210463503.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdurEstMasRelevantesDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrEstMasRelevantes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdurEstMasRelevantesDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrEstMasRelevantes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdur_min\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m61\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_mas_relevante\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7060\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrEstMasRelevantes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdur_media\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m747.6957692082626\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(sortedPageRankGraphVerticesDF.head()[\"pagerank\"] - 1.4427 < 0.01)\n",
    "assert(durEstMasRelevantesDF.count() == 1)\n",
    "assert(len(durEstMasRelevantesDF.columns) == 3)\n",
    "rEstMasRelevantes = durEstMasRelevantesDF.head()\n",
    "assert(rEstMasRelevantes.dur_min == 61)\n",
    "assert(id_mas_relevante == 7060)\n",
    "assert(rEstMasRelevantes.dur_media - 747.6957692082626 < 0.001)\n",
    "assert(rEstMasRelevantes.dur_max == 35130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
